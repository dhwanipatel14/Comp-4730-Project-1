{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFXZEWpXLv4pEKX0LhNSov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhwanipatel14/Comp-4730-Project-1/blob/master/VGG_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TJBIsa-p-ylF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7617c2-bdcf-4e40-ea77-66ceaffb162d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n",
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the essential libraries \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16;\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import os"
      ],
      "metadata": {
        "id": "3_OpV1lp_T-T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading mnist dataset from keras\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "jMOvvlt29_Lp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainX is an array, etc, arraying from 0-255\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "print(trainX.shape, testX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZwiFj6C-C7K",
        "outputId": "8e947aaa-67bb-4577-ae28-2f6ee582fb75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX=np.dstack([trainX] * 3)\n",
        "testX=np.dstack([testX]*3)\n",
        "trainX.shape,testX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_-Xj3s9-FdC",
        "outputId": "dddce05e-1688-43ed-98b2-56ce2ba2c2a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 84), (10000, 28, 84))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape images as per the tensor format required by tensorflow\n",
        "trainX = trainX.reshape(-1, 28,28,3)\n",
        "testX= testX.reshape (-1,28,28,3)\n",
        "trainX.shape,testX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RDVryk_-I4h",
        "outputId": "c4687ed8-e29f-48db-95a1-cc6c9b857e00"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resize the images 48*48 as required by VGG16\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "trainX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in trainX])\n",
        "testX = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in testX])\n",
        "\n",
        "#trainx = preprocess_input(x)\n",
        "trainX.shape, testX.shape\n",
        "classes = np.unique(trainY)\n",
        "num_classes = len(classes)\n",
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxGTlCmo-LdK",
        "outputId": "d1a97bf6-e321-471c-8d09-4a2241644ec6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalise the data and change data type\n",
        "trainX = trainX / 255.\n",
        "testX = testX / 255.\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')"
      ],
      "metadata": {
        "id": "TVxE3V5-_Ae-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Labels to one hot encoded format\n",
        "trainY_one_hot = to_categorical(trainY)\n",
        "testY_one_hot = to_categorical(testY)\n",
        "\n",
        "trainX,valid_X,train_label,valid_label = train_test_split(trainX, trainY_one_hot,test_size=0.2,random_state=13)"
      ],
      "metadata": {
        "id": "dD-LHgAu_DTm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finally check the data size whether it is as per tensorflow and VGG16 requirement\n",
        "trainX.shape,valid_X.shape,train_label.shape,valid_label.shape\n",
        "\n",
        "#define the parameters for instanitaing VGG16 model. \n",
        "IMG_WIDTH = 48\n",
        "IMG_HEIGHT = 48\n",
        "IMG_DEPTH = 3\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "#preprocessing the input \n",
        "trainX = preprocess_input(trainX)\n",
        "valid_X = preprocess_input(valid_X)\n",
        "testX  = preprocess_input (testX)\n",
        "\n",
        "#create base model of VGG16\n",
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbfc16SK_GOl",
        "outputId": "ae4ea921-e6c3-4dbb-9f7a-5e2b51f1d91e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting features\n",
        "train_features = conv_base.predict(np.array(trainX), batch_size=BATCH_SIZE, verbose=1)\n",
        "test_features = conv_base.predict(np.array(testX), batch_size=BATCH_SIZE, verbose=1)\n",
        "val_features = conv_base.predict(np.array(valid_X), batch_size=BATCH_SIZE, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWq_1WUM_KOa",
        "outputId": "b8c40981-a328-4d79-e925-643ed0621b18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000/3000 [==============================] - 1218s 406ms/step\n",
            "625/625 [==============================] - 259s 415ms/step\n",
            "750/750 [==============================] - 302s 403ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the features so that they can be used for future\n",
        "np.savez(\"train_features\", train_features, train_label)\n",
        "np.savez(\"test_features\", test_features, testY)\n",
        "np.savez(\"val_features\", val_features, valid_label)"
      ],
      "metadata": {
        "id": "1JUHsQKIG8R0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_flat = np.reshape(train_features, (48000, 1*1*512))\n",
        "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
        "val_features_flat = np.reshape(val_features, (12000, 1*1*512))"
      ],
      "metadata": {
        "id": "Q1KjY13SHAeO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import callbacks\n",
        "from keras.layers import ELU, PReLU, LeakyReLU"
      ],
      "metadata": {
        "id": "w7WY5cx7HDBP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
        "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
        "NB_EPOCHS = 100\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))\n",
        "model.add(layers.LeakyReLU(alpha=0.1))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "8UXbduQbHRkB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(),metrics=['acc'])"
      ],
      "metadata": {
        "id": "fT8zEwp-HUd2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_learning = callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=2,verbose=1,mode='auto',epsilon=0.0001,cooldown=2,min_lr=0)\n",
        "eary_stopping = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=7,verbose=1,mode='auto')\n",
        "callbacks = [reduce_learning, eary_stopping]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MSWbfqTHXM7",
        "outputId": "3d3a5a6f-516c-41b6-891b-56d760c2c3e8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "history = model.fit(train_features_flat,train_label,epochs=NB_EPOCHS,validation_data=(val_features_flat, valid_label),callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esJFpXm3Ha25",
        "outputId": "c9fa193d-edb5-4aa3-d697-41e41ff2c831"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 1.4070 - acc: 0.4982 - val_loss: 1.0905 - val_acc: 0.5992 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 1.0011 - acc: 0.6505 - val_loss: 0.9357 - val_acc: 0.6780 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8788 - acc: 0.7013 - val_loss: 0.8019 - val_acc: 0.7268 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8149 - acc: 0.7218 - val_loss: 0.7273 - val_acc: 0.7654 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.7700 - acc: 0.7385 - val_loss: 0.7162 - val_acc: 0.7591 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.7364 - acc: 0.7497 - val_loss: 0.7192 - val_acc: 0.7543 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7075 - acc: 0.7599 - val_loss: 0.6831 - val_acc: 0.7756 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6907 - acc: 0.7629 - val_loss: 0.6721 - val_acc: 0.7656 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6629 - acc: 0.7761 - val_loss: 0.6885 - val_acc: 0.7617 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6605 - acc: 0.7743 - val_loss: 0.5810 - val_acc: 0.8076 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.6387 - acc: 0.7819 - val_loss: 0.7133 - val_acc: 0.7458 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1496/1500 [============================>.] - ETA: 0s - loss: 0.6307 - acc: 0.7852\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.6311 - acc: 0.7852 - val_loss: 0.6062 - val_acc: 0.7981 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5507 - acc: 0.8183 - val_loss: 0.5538 - val_acc: 0.8144 - lr: 2.0000e-04\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5451 - acc: 0.8207 - val_loss: 0.5369 - val_acc: 0.8217 - lr: 2.0000e-04\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5407 - acc: 0.8204 - val_loss: 0.5329 - val_acc: 0.8225 - lr: 2.0000e-04\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5366 - acc: 0.8235 - val_loss: 0.5361 - val_acc: 0.8201 - lr: 2.0000e-04\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5337 - acc: 0.8232 - val_loss: 0.5307 - val_acc: 0.8247 - lr: 2.0000e-04\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5298 - acc: 0.8251 - val_loss: 0.5137 - val_acc: 0.8316 - lr: 2.0000e-04\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5267 - acc: 0.8271 - val_loss: 0.5319 - val_acc: 0.8218 - lr: 2.0000e-04\n",
            "Epoch 20/100\n",
            "1498/1500 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.8280\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5238 - acc: 0.8281 - val_loss: 0.5238 - val_acc: 0.8222 - lr: 2.0000e-04\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5035 - acc: 0.8346 - val_loss: 0.5067 - val_acc: 0.8364 - lr: 4.0000e-05\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5025 - acc: 0.8359 - val_loss: 0.5035 - val_acc: 0.8381 - lr: 4.0000e-05\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5014 - acc: 0.8369 - val_loss: 0.5070 - val_acc: 0.8347 - lr: 4.0000e-05\n",
            "Epoch 24/100\n",
            "1499/1500 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.8352\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5012 - acc: 0.8353 - val_loss: 0.5037 - val_acc: 0.8359 - lr: 4.0000e-05\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4968 - acc: 0.8389 - val_loss: 0.4992 - val_acc: 0.8366 - lr: 8.0000e-06\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4964 - acc: 0.8390 - val_loss: 0.4986 - val_acc: 0.8364 - lr: 8.0000e-06\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4961 - acc: 0.8383 - val_loss: 0.4986 - val_acc: 0.8381 - lr: 8.0000e-06\n",
            "Epoch 28/100\n",
            "1491/1500 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.8394\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4959 - acc: 0.8394 - val_loss: 0.4990 - val_acc: 0.8374 - lr: 8.0000e-06\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4950 - acc: 0.8387 - val_loss: 0.4981 - val_acc: 0.8388 - lr: 1.6000e-06\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4949 - acc: 0.8390 - val_loss: 0.4981 - val_acc: 0.8388 - lr: 1.6000e-06\n",
            "Epoch 31/100\n",
            "1497/1500 [============================>.] - ETA: 0s - loss: 0.4947 - acc: 0.8395\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4949 - acc: 0.8394 - val_loss: 0.4981 - val_acc: 0.8388 - lr: 1.6000e-06\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4947 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8392 - lr: 3.2000e-07\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4947 - acc: 0.8392 - val_loss: 0.4979 - val_acc: 0.8390 - lr: 3.2000e-07\n",
            "Epoch 34/100\n",
            "1496/1500 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8391\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4947 - acc: 0.8391 - val_loss: 0.4979 - val_acc: 0.8391 - lr: 3.2000e-07\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8391 - lr: 6.4000e-08\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8389 - lr: 6.4000e-08\n",
            "Epoch 37/100\n",
            "1497/1500 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.8393\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8389 - lr: 6.4000e-08\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8389 - lr: 1.2800e-08\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8389 - lr: 1.2800e-08\n",
            "Epoch 40/100\n",
            "1494/1500 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8392\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4946 - acc: 0.8392 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 1.2800e-08\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 2.5600e-09\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4946 - acc: 0.8392 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 2.5600e-09\n",
            "Epoch 43/100\n",
            "1492/1500 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8394\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4946 - acc: 0.8392 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 2.5600e-09\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 5.1200e-10\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 5.1200e-10\n",
            "Epoch 46/100\n",
            "1497/1500 [============================>.] - ETA: 0s - loss: 0.4947 - acc: 0.8392\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 5.1200e-10\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 1.0240e-10\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4946 - acc: 0.8393 - val_loss: 0.4979 - val_acc: 0.8388 - lr: 1.0240e-10\n",
            "Epoch 48: early stopping\n"
          ]
        }
      ]
    }
  ]
}